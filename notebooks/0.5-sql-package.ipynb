{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Package\n",
    "\n",
    "Provides simple functionality to interact with a PostgreSQL server using Python classes.\n",
    "\n",
    "**Overview of functionality:**\n",
    "* Database(self, user, password, host, dbname, port)\n",
    "    * properties\n",
    "        * user\n",
    "        * password\n",
    "        * host\n",
    "        * dbname\n",
    "        * port\n",
    "    * methods\n",
    "        * create(name) x\n",
    "        * connect()\n",
    "        * drop(name)\n",
    "* Table(self, dbname, table, schema)\n",
    "    * accepts db properties\n",
    "    * properties\n",
    "        * connect() --> inherited\n",
    "        * fetch_data(sql, con, parse_dates)\n",
    "        * get_names()\n",
    "        * format_names(char_dict)\n",
    "        * update_names(names_dict)\n",
    "        * add_columns(columns_list, type=None)\n",
    "        * compare_column_order(dataframe)\n",
    "        * match_columns(dataframe)\n",
    "        * save_csv(data, local_path, match_column_order=True)\n",
    "        * update_values(local_path, container_path)\n",
    "        * update_types(types_dict)\n",
    "        * close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "#sys.path[0] = str(Path(__file__).resolve().parents[2]) # Set path for custom modules\n",
    "import warnings\n",
    "from io import StringIO\n",
    "\n",
    "# Set path for modules\n",
    "sys.path[0] = '../'\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# SQL libraries\n",
    "import psycopg2\n",
    "from src.pipeline.dictionaries import types_dict, replace_map\n",
    "from src.pipeline.transform_data import create_full_address, split_lat_long\n",
    "from src.toolkits.geospatial import geocode_from_address\n",
    "#from src.toolkits.postgresql import Database, Table\n",
    "\n",
    "# Set notebook display options\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Get project root directory\n",
    "#root_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# if modulename not in sys.modules: print...\n",
    "load_dotenv(find_dotenv());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database():\n",
    "    \n",
    "    def __init__(self, user=\"postgres\", password=\"postgres\",\n",
    "                 dbname=None, host=\"localhost\", port=5432):\n",
    "\n",
    "        # Loaded from .env if not explicit\n",
    "        self.user = os.getenv(\"POSTGRES_USER\") or user\n",
    "        self.password = os.getenv(\"POSTGRES_PASSWORD\") or password\n",
    "        self.dbname = os.getenv(\"POSTGRES_DB\") or dbname\n",
    "        self.host = os.getenv(\"DB_HOST\") or host\n",
    "        self.port = os.getenv(\"DB_PORT\") or port\n",
    "        \n",
    "        \n",
    "    def _connect(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Connects to PostgreSQL database using psycopg2 driver. Same\n",
    "        arguments as psycopg2.connect().\n",
    "\n",
    "        Params\n",
    "        --------\n",
    "        dbname\n",
    "        user\n",
    "        password\n",
    "        host\n",
    "        port\n",
    "        connect_timeout\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            con = psycopg2.connect(dbname=self.dbname,\n",
    "                                   user=self.user,\n",
    "                                   password=self.password,\n",
    "                                    host=self.host, \n",
    "                                    port=self.port,\n",
    "                                  connect_timeout=3)            \n",
    "        except Exception as e:\n",
    "            print('Error:', e)\n",
    "            return None\n",
    "\n",
    "        return con\n",
    "    \n",
    "    @property\n",
    "    def _con(self):\n",
    "        try:\n",
    "            con = self._connect()\n",
    "            print('Connected as user \"{}\" to database \"{}\" on http://{}:{}.'.format(self.user,self.dbname,\n",
    "                                                               self.host,self.port))\n",
    "            con.close()\n",
    "        except Exception as e:\n",
    "            con.rollback()\n",
    "            print('Error:', e)\n",
    "        finally:\n",
    "            if con is not None:\n",
    "                con.close()\n",
    "                \n",
    "                \n",
    "    def _run_query(self, sql):\n",
    "        \n",
    "        try:\n",
    "            con = self._connect()\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)            \n",
    "            \n",
    "        try:\n",
    "            cur = con.cursor()\n",
    "            cur.execute(sql)\n",
    "            con.commit()\n",
    "            cur.close()\n",
    "            print('Query successful on database \"{}\".'.format(self.dbname))\n",
    "        except Exception as e:\n",
    "            con.rollback()\n",
    "            print(\"Error:\", e)\n",
    "        finally:\n",
    "            if con is not None:\n",
    "                con.close()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def create_table(self, table_name, types_dict, id_col, columns=None):\n",
    "        \n",
    "        # Append id_col to selected columns\n",
    "        columns = None if not columns else set([id_col] + columns)\n",
    "        \n",
    "        # Subsets types_dict by columns argument and formats into string if no columns are specified\n",
    "        types_dict = types_dict if not columns else {key:value for key, value in types_dict.items() if key in set(columns)}\n",
    "        names = ',\\n\\t'.join(['{key} {val}'.format(key=key, val=val) for key, val in types_dict.items()])\n",
    "        \n",
    "        # Build queries\n",
    "        sql = 'CREATE TABLE {table_name} (\\n\\t{names}\\n);\\n\\n' \\\n",
    "                            .format(table_name=table_name, names=names) # + sql\n",
    "        \n",
    "        # Execute query\n",
    "        self._run_query(sql)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def drop_table(self, table_name):\n",
    "        \n",
    "        # Build queries\n",
    "        sql = 'DROP TABLE IF EXISTS {table_name};\\n\\n'.format(table_name=table_name)\n",
    "        \n",
    "        # Execute query\n",
    "        self._run_query(sql)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _subset_types_dict(self, types_dict, columns):\n",
    "        \n",
    "        types_dict = types_dict if not columns else {key:value for key, value in types_dict.items() if key in set(columns)}\n",
    "        columns = self.get_names().tolist() if not columns else columns\n",
    "        \n",
    "        return types_dict, columns\n",
    "    \n",
    "\n",
    "    def _create_temp_table(self, types_dict, id_col, columns=None):\n",
    "        \n",
    "        types_dict, _ = self._subset_types_dict(types_dict, columns)\n",
    "        \n",
    "        # Append id_col to selected columns\n",
    "        columns = None if not columns else [id_col] + columns\n",
    "        \n",
    "        # CREATE TABLE query\n",
    "        tmp_table = \"tmp_\" + self.table\n",
    "        \n",
    "        # Subsets types_dict by columns argument and formats into string if no columns are specified\n",
    "        names = ',\\n\\t'.join(['{key} {val}'.format(key=key, val=val) for key, val in types_dict.items()])\n",
    "        \n",
    "        # Build queries\n",
    "        sql = 'DROP TABLE IF EXISTS {tmp_table};\\n\\n'.format(tmp_table=tmp_table)\n",
    "        sql = sql + 'CREATE TABLE {tmp_table} (\\n\\t{names}\\n);\\n\\n' \\\n",
    "                                .format(tmp_table=tmp_table, names=names)\n",
    "        \n",
    "        # Execute query\n",
    "        self._run_query(sql)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    ## List tables\n",
    "    def list_tables(self):\n",
    "        \n",
    "        sql = \"\"\"\n",
    "        SELECT tablename FROM pg_catalog.pg_tables\n",
    "        WHERE schemaname NOT IN ('pg_catalog', 'information_schema');\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            con = self._connect()\n",
    "            cur = con.cursor()\n",
    "            cur.execute(sql)\n",
    "        except Exception as e:\n",
    "            con.rollback()\n",
    "            print(\"Error:\", e)\n",
    "            \n",
    "        results = cur.fetchall()\n",
    "        \n",
    "        tables = []\n",
    "        \n",
    "        for result in results:\n",
    "            tables.append(*result)\n",
    "            \n",
    "        return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "permits = Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Table class ####\n",
    "\n",
    "class Table(Database):\n",
    "    def __init__(self, name, user=\"postgres\", password=\"postgres\",\n",
    "                 dbname=None, host=\"localhost\", port=5432):\n",
    "        \n",
    "        super().__init__(user, password, dbname, host, port)\n",
    "        \n",
    "        self.table = name\n",
    "        \n",
    "        # Loaded from .env if not explicit\n",
    "        self.user = os.getenv(\"POSTGRES_USER\") or user\n",
    "        self.password = os.getenv(\"POSTGRES_PASSWORD\") or password\n",
    "        self.dbname = os.getenv(\"POSTGRES_DB\") or dbname\n",
    "        self.host = os.getenv(\"DB_HOST\") or host\n",
    "        self.port = os.getenv(\"DB_PORT\") or port\n",
    "\n",
    "    \n",
    "    # Connect to database\n",
    "    def __connect(self):\n",
    "        return super(Table, self)._connect()\n",
    "    \n",
    "    # Check info on connection\n",
    "    def __con(self):\n",
    "        return super(Table, self)._con\n",
    "    \n",
    "    # Run query\n",
    "    def __run_query(self, sql):\n",
    "        return super(Table, self)._run_query(sql)\n",
    "    \n",
    "    def __subset_types_dict(self, types_dict, columns):\n",
    "        return super(Table, self)._subset_types_dict(types_dict, columns)\n",
    "\n",
    "    def __create_temp_table(self, types_dict, id_col, columns):\n",
    "        return super(Table, self)._create_temp_table(types_dict, id_col, columns)\n",
    "    \n",
    "    \n",
    "    # Fetch data from sql query\n",
    "    def fetch_data(self, sql=None, coerce_float=False, parse_dates=None):\n",
    "        \n",
    "        sql = sql or \"SELECT * FROM {};\".format(self.table)\n",
    "        \n",
    "        con = self.__connect()\n",
    "        \n",
    "        # Fetch fresh data\n",
    "        data = pd.read_sql_query(sql=sql, con=con, coerce_float=coerce_float, parse_dates=parse_dates)\n",
    "\n",
    "        # Replace None with np.nan\n",
    "        data.fillna(np.nan, inplace=True)\n",
    "        \n",
    "        # Close db connection\n",
    "        con.close()\n",
    "\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    # Get names of column\n",
    "    def get_names(self):\n",
    "        \n",
    "        # Specific query to retrieve table names\n",
    "        sql = \"SELECT * FROM information_schema.columns WHERE table_name = N'{}'\".format(self.table)\n",
    "        \n",
    "        # Run query and extract\n",
    "        try:\n",
    "            con = self.__connect()\n",
    "            data = pd.read_sql_query(sql, con)\n",
    "            column_series = data['column_name']\n",
    "            con.close()\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "    \n",
    "        return column_series\n",
    "\n",
    "    \n",
    "    # Get types of columns, returns dict\n",
    "    def get_types(self, as_dataframe=False):\n",
    "        \n",
    "        # Specific query to retrieve table names\n",
    "        sql = \"\"\"\n",
    "        SELECT column_name, \n",
    "        CASE \n",
    "            WHEN domain_name is not null then domain_name\n",
    "            WHEN data_type='character varying' THEN 'varchar('||character_maximum_length||')'\n",
    "            WHEN data_type='character' THEN 'char('||character_maximum_length||')'\n",
    "            WHEN data_type='numeric' THEN 'numeric'\n",
    "            ELSE data_type\n",
    "        END AS type\n",
    "        FROM information_schema.columns WHERE table_name = 'permits_raw';\n",
    "        \"\"\"\n",
    "        \n",
    "        # Run query and extract\n",
    "        try:\n",
    "            con = self.__connect()\n",
    "            data = pd.read_sql_query(sql, con)\n",
    "            con.close()\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "        \n",
    "        if as_dataframe:\n",
    "            data['type'] = data['type'].str.upper()\n",
    "            return data\n",
    "        \n",
    "        types_dict = dict(zip(data['column_name'], data['type'].str.upper()))\n",
    "        \n",
    "        return types_dict\n",
    "    \n",
    "    \n",
    "    # Update column names in db table\n",
    "    def _update_table_names(self, series):\n",
    "\n",
    "        # Extract current columns in table\n",
    "        old_columns = self.get_names()\n",
    "\n",
    "        # Create list of reformatted columns to replace old columns \n",
    "        new_columns = series\n",
    "\n",
    "        # SQL query string to change column names\n",
    "        sql = 'ALTER TABLE {} '.format(self.table) + 'RENAME \"{old_name}\" to {new_name};'\n",
    "\n",
    "        sql_query = []\n",
    "\n",
    "        # Iterate through old column names and replace each with reformatted name \n",
    "        for idx, name in old_columns.iteritems():\n",
    "            sql_query.append(sql.format(old_name=name, new_name=new_columns[idx]))\n",
    "\n",
    "        # Join list to string\n",
    "        sql_query = '\\n'.join(sql_query)\n",
    "\n",
    "        return sql_query\n",
    "    \n",
    "\n",
    "    # Standardize column names using dictionary of character replacements\n",
    "    def format_table_names(self, replace_map, update=False):\n",
    "        \n",
    "        series = self.get_names()\n",
    "        \n",
    "        def replace_chars(text):\n",
    "            for oldchar, newchar in replace_map.items():\n",
    "                text = text.replace(oldchar, newchar).lower()\n",
    "            return text\n",
    "        \n",
    "        series = series.apply(replace_chars)  \n",
    "        \n",
    "        if not update:\n",
    "            warnings.warn('No changes made. Set \"update=True\" to run query on database.')\n",
    "            return series.apply(replace_chars)\n",
    "        \n",
    "        else:\n",
    "            sql_query = self._update_table_names(series=series)\n",
    "            \n",
    "            # Execute query\n",
    "            self.__run_query(sql_query)\n",
    "            \n",
    "            return self\n",
    "                    \n",
    "\n",
    "    # Add new columns to database\n",
    "    def add_columns_from_data(self, data):\n",
    "        \n",
    "        # Get names of current columns in PostgreSQL table\n",
    "        current_names = self.get_names().tolist()\n",
    "\n",
    "        # Get names of updated table not in current table\n",
    "        updated_names = data.columns.tolist()\n",
    "        new_names = list(set(updated_names) - set(current_names))\n",
    "\n",
    "        # Check names list is not empty\n",
    "        if not new_names:\n",
    "            print(\"Table columns are already up to date.\")\n",
    "            return\n",
    "\n",
    "        # Format strings for query\n",
    "        alter_table_sql = \"ALTER TABLE {db_table}\\n\"\n",
    "        add_column_sql = \"\\tADD COLUMN {column} TEXT,\\n\"\n",
    "\n",
    "        # Create a list and append ADD column statements\n",
    "        sql_query = [alter_table_sql.format(db_table=self.table)]\n",
    "        for name in new_names:\n",
    "            sql_query.append(add_column_sql.format(column=name))\n",
    "\n",
    "        # Join into one string\n",
    "        sql = ''.join(sql_query)[:-2] + \";\"\n",
    "\n",
    "        # Execute query\n",
    "        self.__run_query(sql)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    # Check whether dataframe columns match database table columns before running queries\n",
    "    def _match_column_order(self, data):\n",
    "        \n",
    "        # Get columns from database as list\n",
    "        db_columns = self.get_names().tolist()\n",
    "\n",
    "        # Select columns from dataframe as list\n",
    "        data_columns = data.columns.tolist()\n",
    "        \n",
    "        if set(data_columns) == set(db_columns):\n",
    "            if data_columns != db_columns:\n",
    "                print('Rearranged dataframe columns to match table \"{}\".'.format(self.table))\n",
    "                data = data[db_columns]\n",
    "                return True\n",
    "            else:\n",
    "                print('Dataframe columns already match table \"{}\".'.format(self.table))\n",
    "                return True\n",
    "        else:\n",
    "            if len(data_columns) > len(db_columns):\n",
    "                print('Dataframe has columns not in table \"{}\":'.format(self.table))\n",
    "                print(list(set(data_columns) - set(db_columns)))\n",
    "                return False\n",
    "            else:\n",
    "                print('Dataframe missing columns that are in table \"{}\":'.format(self.table))\n",
    "                print(list(set(db_columns) - set(data_columns)))\n",
    "                return False\n",
    "        \n",
    "    \n",
    "    def _copy_from_dataframe(self, data, id_col, columns=None):\n",
    "        \n",
    "        if self._match_column_order(data):\n",
    "        \n",
    "            try:\n",
    "                con = self.__connect()\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "            \n",
    "            columns = data.columns.tolist() if not columns else columns\n",
    "            temp_table = \"tmp_\" + self.table\n",
    "            data_buffer = StringIO(data.to_csv(header=False, index=False, sep=','))\n",
    "\n",
    "            try:\n",
    "                cur = con.cursor()\n",
    "                data_buffer.read()\n",
    "                cur.copy_from(file=data_buffer, table=temp_table, columns=columns)\n",
    "                data_buffer.close()\n",
    "                con.commit()\n",
    "                cur.close()\n",
    "                print('Copy successful on table \"{}\".'.format(self.table))\n",
    "            except Exception as e:\n",
    "                con.rollback()\n",
    "                print(\"Error:\", e)\n",
    "            finally:\n",
    "                if con is not None:\n",
    "                    con.close()\n",
    "                \n",
    "        return self\n",
    "                \n",
    "        \n",
    "    def _update_from_temp(self, id_col, columns=None):\n",
    "        \n",
    "        temp_table = \"tmp_\" + self.table\n",
    "        columns = self.get_names().tolist() if not columns else columns\n",
    "        sql_update = 'UPDATE {table}\\n'.format(table=self.table)\n",
    "        sql_set = [\"SET \"]\n",
    "        \n",
    "        for name in columns:\n",
    "            line = \"{name} = {tmp_name},\\n\\t\".format(name=name, tmp_name=temp_table + '.' + name)\n",
    "            sql_set.append(line)\n",
    "\n",
    "        sql_set = ''.join(sql_set)\n",
    "        sql_set = sql_set[:-3] + \"\\n\"\n",
    "\n",
    "        sql_from = \"FROM {temp_table}\\nWHERE {this_table}.{id_col} = {temp_table}.{id_col};\\n\\n\" \\\n",
    "                            .format(temp_table=temp_table, this_table=self.table, id_col=id_col)\n",
    "        sql_drop = 'DROP TABLE {};\\n'.format(temp_table)\n",
    "                \n",
    "        sql = sql_update + sql_set + sql_from + sql_drop\n",
    "        \n",
    "        # Execute query\n",
    "        self.__run_query(sql)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "                \n",
    "    # Builds a query to update postgres from a csv file\n",
    "    def update_values(self, data, id_col, types_dict, columns=None, sep=','):\n",
    "        \n",
    "        columns = self.get_names().tolist() if not columns else [id_col] + columns\n",
    "        params = {\"id_col\":id_col, \"columns\":columns}\n",
    "        \n",
    "        self.__create_temp_table(types_dict=types_dict, **params) \\\n",
    "                        ._copy_from_dataframe(data=data, **params) \\\n",
    "                        ._update_from_temp(**params)\n",
    "        \n",
    "    \n",
    "    # Updates column types in PostgreSQL database\n",
    "    def update_types(self, types_dict, columns=None):\n",
    "\n",
    "        types_dict, columns = self.__subset_types_dict(types_dict, columns)\n",
    "        \n",
    "        # Define SQL update queries\n",
    "        sql_alter_table = \"ALTER TABLE public.{}\\n\\t\".format(self.table)\n",
    "\n",
    "        # Update types\n",
    "        sql_update_types = []\n",
    "        \n",
    "        for column, col_type in types_dict.items():\n",
    "            if \"DATE\" in col_type.upper():\n",
    "                sql_string = \"ALTER {column} TYPE {col_type} USING {column}::\" + \"{col_type},\\n\\t\"\n",
    "            elif \"INT\" in col_type.upper() or \"NUM\" in col_type.upper():\n",
    "                sql_string = \"ALTER {column} TYPE {col_type} USING {column}::text::numeric::{col_type},\\n\\t\"\n",
    "            elif \"NUM\" in col_type.upper():\n",
    "                sql_string = \"ALTER {column} TYPE {col_type} USING {column}::text::numeric::{col_type},\\n\\t\"\n",
    "            else:\n",
    "                sql_string = \"ALTER {column} TYPE {col_type},\\n\\t\"\n",
    "\n",
    "            sql_alter_column = sql_string.format(column=column, col_type=col_type)\n",
    "            sql_update_types.append(sql_alter_column)\n",
    "\n",
    "        # Join strings to create full sql query\n",
    "        sql_update_types = sql_alter_table + ''.join(sql_update_types)\n",
    "\n",
    "        # Replace very last character with \";\"\n",
    "        sql = sql_update_types[:-3] + \";\"\n",
    "\n",
    "        self.__run_query(sql)\n",
    "            \n",
    "        return \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pipeline\n",
    "\n",
    "1. Standardize table names.<br>\n",
    "2. Fetch raw data and transform:\n",
    "    - Concatenate address columns\n",
    "    - Geocode missing coordinates using street address\n",
    "    - Extract latitude and longitude from coordinates into their own columns\n",
    "3. Update the table with the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "permits_raw = Table(name=\"permits_raw\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize table names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query successful on database \"permits\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Table at 0x110c6b5d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permits_raw.format_table_names(replace_map=replace_map, update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = permits_raw.fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-b65f1f0f0b1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_full_address\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/gregory/Documents/00 Data Projects/project-portfolio/permits-data/src/pipeline/transform_data.py\u001b[0m in \u001b[0;36mcreate_full_address\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Replace empty strings with NaN values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maddress_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maddress_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "create_full_address(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: column \"assessor_book\" does not exist\n",
      "LINE 2:  ALTER assessor_book TYPE SMALLINT USING assessor_book::text...\n",
      "                                                 ^\n",
      "HINT:  Perhaps you meant to reference the column \"permits_raw.Assessor Book\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "permits_raw.update_types(types_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assessor Book</th>\n",
       "      <th>Assessor Page</th>\n",
       "      <th>Assessor Parcel</th>\n",
       "      <th>Tract</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Reference # (Old Permit #)</th>\n",
       "      <th>PCIS Permit #</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status Date</th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Permit Sub-Type</th>\n",
       "      <th>Permit Category</th>\n",
       "      <th>Project Number</th>\n",
       "      <th>Event Code</th>\n",
       "      <th>Initiating Office</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>Address Start</th>\n",
       "      <th>Address Fraction Start</th>\n",
       "      <th>Address End</th>\n",
       "      <th>Address Fraction End</th>\n",
       "      <th>Street Direction</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Street Suffix</th>\n",
       "      <th>Suffix Direction</th>\n",
       "      <th>Unit Range Start</th>\n",
       "      <th>Unit Range End</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Work Description</th>\n",
       "      <th>Valuation</th>\n",
       "      <th>Floor Area-L.A. Zoning Code Definition</th>\n",
       "      <th># of Residential Dwelling Units</th>\n",
       "      <th># of Accessory Dwelling Units</th>\n",
       "      <th># of Stories</th>\n",
       "      <th>Contractor's Business Name</th>\n",
       "      <th>Contractor Address</th>\n",
       "      <th>Contractor City</th>\n",
       "      <th>Contractor State</th>\n",
       "      <th>License Type</th>\n",
       "      <th>License #</th>\n",
       "      <th>Principal First Name</th>\n",
       "      <th>Principal Middle Name</th>\n",
       "      <th>Principal Last Name</th>\n",
       "      <th>License Expiration Date</th>\n",
       "      <th>Applicant First Name</th>\n",
       "      <th>Applicant Last Name</th>\n",
       "      <th>Applicant Business Name</th>\n",
       "      <th>Applicant Address 1</th>\n",
       "      <th>Applicant Address 2</th>\n",
       "      <th>Applicant Address 3</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>Floor Area-L.A. Building Code Definition</th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>Council District</th>\n",
       "      <th>Latitude/Longitude</th>\n",
       "      <th>Applicant Relationship</th>\n",
       "      <th>Existing Code</th>\n",
       "      <th>Proposed Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4317</td>\n",
       "      <td>003</td>\n",
       "      <td>***</td>\n",
       "      <td>TR 30210-C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15044-90000-08405</td>\n",
       "      <td>Permit Finaled</td>\n",
       "      <td>09/10/2015</td>\n",
       "      <td>HVAC</td>\n",
       "      <td>1 or 2 Family Dwelling</td>\n",
       "      <td>No Plan Check</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>08/18/2015</td>\n",
       "      <td>1823</td>\n",
       "      <td>1/2</td>\n",
       "      <td>1823</td>\n",
       "      <td>1/2</td>\n",
       "      <td>S</td>\n",
       "      <td>THAYER</td>\n",
       "      <td>AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONDITIONED AIRE MECHANICAL &amp; ENGINEERING INC</td>\n",
       "      <td>18650 PARTHENIA STREET</td>\n",
       "      <td>NORTHRIDGE</td>\n",
       "      <td>CA</td>\n",
       "      <td>C20</td>\n",
       "      <td>532440</td>\n",
       "      <td>BRETT</td>\n",
       "      <td>MOORE</td>\n",
       "      <td>HOFFER</td>\n",
       "      <td>06/30/2016</td>\n",
       "      <td>BRETT</td>\n",
       "      <td>HOFFER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18650 PARTHENIA ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORTHRIDGE, CA</td>\n",
       "      <td>R3-1-O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2671.00</td>\n",
       "      <td>5</td>\n",
       "      <td>(34.05474, -118.42628)</td>\n",
       "      <td>Net Applicant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5005</td>\n",
       "      <td>010</td>\n",
       "      <td>017</td>\n",
       "      <td>CHESTERFIELD SQUARE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>465</td>\n",
       "      <td>16SL57806</td>\n",
       "      <td>16016-70000-02464</td>\n",
       "      <td>Permit Finaled</td>\n",
       "      <td>08/01/2017</td>\n",
       "      <td>Bldg-Alter/Repair</td>\n",
       "      <td>1 or 2 Family Dwelling</td>\n",
       "      <td>No Plan Check</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTH LA</td>\n",
       "      <td>02/04/2016</td>\n",
       "      <td>2122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>54TH</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90062</td>\n",
       "      <td>General rehabilitation for single family dwell...</td>\n",
       "      <td>40000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OWNER-BUILDER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>JAVIER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TALAMANTES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JAVIER</td>\n",
       "      <td>TALAMANTES</td>\n",
       "      <td>OWNER-BUILDER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C2-1VL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2325.00</td>\n",
       "      <td>8</td>\n",
       "      <td>(33.99307, -118.31668)</td>\n",
       "      <td>Owner-Bldr</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5154</td>\n",
       "      <td>023</td>\n",
       "      <td>022</td>\n",
       "      <td>SUN-SET TRACT</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>14VN81535</td>\n",
       "      <td>14016-20000-13092</td>\n",
       "      <td>Issued</td>\n",
       "      <td>08/13/2014</td>\n",
       "      <td>Bldg-Alter/Repair</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Plan Check</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VAN NUYS</td>\n",
       "      <td>08/13/2014</td>\n",
       "      <td>415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>BURLINGTON</td>\n",
       "      <td>AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-30</td>\n",
       "      <td>1-30</td>\n",
       "      <td>90057</td>\n",
       "      <td>PHOTOVOLTAIC SOLAR PANELS ON ROOF OF (E) APT BLDG</td>\n",
       "      <td>37000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERMACITY CONSTRUCTION CORP</td>\n",
       "      <td>5570 W WASHINGTON BLVD</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CA</td>\n",
       "      <td>B</td>\n",
       "      <td>827864</td>\n",
       "      <td>JONATHAN</td>\n",
       "      <td>SAUL</td>\n",
       "      <td>PORT</td>\n",
       "      <td>11/30/2015</td>\n",
       "      <td>LINDA</td>\n",
       "      <td>MARTON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710 WILSHIRE BLVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SANTA MONICA, CA</td>\n",
       "      <td>R4-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2089.04</td>\n",
       "      <td>1</td>\n",
       "      <td>(34.06012, -118.26997)</td>\n",
       "      <td>Agent for Owner</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Assessor Book Assessor Page Assessor Parcel                Tract Block  \\\n",
       "0          4317           003             ***           TR 30210-C   NaN   \n",
       "1          5005           010             017  CHESTERFIELD SQUARE   NaN   \n",
       "2          5154           023             022        SUN-SET TRACT     D   \n",
       "\n",
       "    Lot Reference # (Old Permit #)      PCIS Permit #          Status  \\\n",
       "0  LT 1                        NaN  15044-90000-08405  Permit Finaled   \n",
       "1   465                  16SL57806  16016-70000-02464  Permit Finaled   \n",
       "2    13                  14VN81535  14016-20000-13092          Issued   \n",
       "\n",
       "  Status Date        Permit Type         Permit Sub-Type Permit Category  \\\n",
       "0  09/10/2015               HVAC  1 or 2 Family Dwelling   No Plan Check   \n",
       "1  08/01/2017  Bldg-Alter/Repair  1 or 2 Family Dwelling   No Plan Check   \n",
       "2  08/13/2014  Bldg-Alter/Repair               Apartment      Plan Check   \n",
       "\n",
       "  Project Number  Event Code Initiating Office  Issue Date Address Start  \\\n",
       "0            NaN         NaN          INTERNET  08/18/2015          1823   \n",
       "1            NaN         NaN          SOUTH LA  02/04/2016          2122   \n",
       "2            NaN         NaN          VAN NUYS  08/13/2014           415   \n",
       "\n",
       "  Address Fraction Start Address End Address Fraction End Street Direction  \\\n",
       "0                    1/2        1823                  1/2                S   \n",
       "1                    NaN        2122                  NaN                W   \n",
       "2                    NaN         415                  NaN                S   \n",
       "\n",
       "  Street Name Street Suffix Suffix Direction Unit Range Start Unit Range End  \\\n",
       "0      THAYER           AVE              NaN              NaN            NaN   \n",
       "1        54TH            ST              NaN              NaN            NaN   \n",
       "2  BURLINGTON           AVE              NaN             1-30           1-30   \n",
       "\n",
       "  Zip Code                                   Work Description Valuation  \\\n",
       "0    90025                                                NaN       NaN   \n",
       "1    90062  General rehabilitation for single family dwell...  40000.00   \n",
       "2    90057  PHOTOVOLTAIC SOLAR PANELS ON ROOF OF (E) APT BLDG  37000.00   \n",
       "\n",
       "  Floor Area-L.A. Zoning Code Definition # of Residential Dwelling Units  \\\n",
       "0                                    NaN                             NaN   \n",
       "1                                    NaN                             NaN   \n",
       "2                                    NaN                             NaN   \n",
       "\n",
       "   # of Accessory Dwelling Units # of Stories  \\\n",
       "0                            NaN          NaN   \n",
       "1                            NaN          NaN   \n",
       "2                            NaN          NaN   \n",
       "\n",
       "                      Contractor's Business Name      Contractor Address  \\\n",
       "0  CONDITIONED AIRE MECHANICAL & ENGINEERING INC  18650 PARTHENIA STREET   \n",
       "1                                  OWNER-BUILDER                     NaN   \n",
       "2                    PERMACITY CONSTRUCTION CORP  5570 W WASHINGTON BLVD   \n",
       "\n",
       "  Contractor City Contractor State License Type License #  \\\n",
       "0      NORTHRIDGE               CA          C20    532440   \n",
       "1             NaN              NaN           NA         0   \n",
       "2     LOS ANGELES               CA            B    827864   \n",
       "\n",
       "  Principal First Name Principal Middle Name Principal Last Name  \\\n",
       "0                BRETT                 MOORE              HOFFER   \n",
       "1               JAVIER                   NaN          TALAMANTES   \n",
       "2             JONATHAN                  SAUL                PORT   \n",
       "\n",
       "  License Expiration Date Applicant First Name Applicant Last Name  \\\n",
       "0              06/30/2016                BRETT              HOFFER   \n",
       "1                     NaN               JAVIER          TALAMANTES   \n",
       "2              11/30/2015                LINDA              MARTON   \n",
       "\n",
       "  Applicant Business Name Applicant Address 1 Applicant Address 2  \\\n",
       "0                     NaN  18650 PARTHENIA ST                 NaN   \n",
       "1           OWNER-BUILDER                 NaN                 NaN   \n",
       "2                     NaN   710 WILSHIRE BLVD                 NaN   \n",
       "\n",
       "  Applicant Address 3    Zone Occupancy  \\\n",
       "0      NORTHRIDGE, CA  R3-1-O       NaN   \n",
       "1                 NaN  C2-1VL       NaN   \n",
       "2    SANTA MONICA, CA    R4-1       NaN   \n",
       "\n",
       "  Floor Area-L.A. Building Code Definition Census Tract Council District  \\\n",
       "0                                        0      2671.00                5   \n",
       "1                                      NaN      2325.00                8   \n",
       "2                                      NaN      2089.04                1   \n",
       "\n",
       "       Latitude/Longitude Applicant Relationship Existing Code Proposed Code  \n",
       "0  (34.05474, -118.42628)          Net Applicant           NaN           NaN  \n",
       "1  (33.99307, -118.31668)             Owner-Bldr             1           NaN  \n",
       "2  (34.06012, -118.26997)        Agent for Owner             5           NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
